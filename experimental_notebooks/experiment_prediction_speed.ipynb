{"cells":[{"cell_type":"markdown","source":["# Testing whether RandDense models have different prediction speeds than their standard counterparts\n","See Section 6a of the manuscript"],"metadata":{"id":"7wGc0SBwVu_D"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2380,"status":"ok","timestamp":1665652458581,"user":{"displayName":"William Yik","userId":"05457595871295349459"},"user_tz":420},"id":"4xdElVALlEjm","outputId":"5e36a29f-b85d-4358-e270-64bb0a2c0b6f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/USC Random NN')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4710,"status":"ok","timestamp":1665652463281,"user":{"displayName":"William Yik","userId":"05457595871295349459"},"user_tz":420},"id":"vVKtBi7olqg2","outputId":"ad6d4056-014c-49f7-e5bd-21e7d578672a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting importlib-metadata==4.13.0\n","  Using cached importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n","Collecting typing-extensions>=3.6.4\n","  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n","Collecting zipp>=0.5\n","  Using cached zipp-3.9.0-py3-none-any.whl (5.8 kB)\n","Installing collected packages: zipp, typing-extensions, importlib-metadata\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","thinc 8.1.3 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\n","spacy 3.4.1 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\n","confection 0.0.3 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\u001b[0m\n","Successfully installed importlib-metadata-5.0.0 typing-extensions-4.4.0 zipp-3.9.0\n"]}],"source":["# To resolve an xarray bug\n","!pip install -I importlib-metadata==4.13.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AdqNxi9bEhsN"},"outputs":[],"source":["!pip install eofs --quiet\n","import numpy as np\n","import xarray as xr\n","import pandas as pd\n","from utils import *\n","from utils_cnn_lstm import *\n","results_path = results_path + 'prediction_speed/'\n","\n","from random_nn import *\n","import keras\n","from keras import Sequential, Model\n","from keras.layers import *\n","from keras.callbacks import EarlyStopping\n","import tensorflow as tf\n","from tensorflow.keras.utils import plot_model\n","tf.get_logger().setLevel('ERROR')\n","import absl.logging\n","absl.logging.set_verbosity(absl.logging.ERROR)\n","from IPython.display import display\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.ticker import AutoMinorLocator\n","import seaborn as sns\n","import timeit\n","from scipy import stats\n","\n","tf.keras.utils.set_random_seed(21)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23046,"status":"ok","timestamp":1665652490543,"user":{"displayName":"William Yik","userId":"05457595871295349459"},"user_tz":420},"id":"0rBwtFMiUQ-_","outputId":"ceac63e4-5873-48c7-b7a2-5440d6857c33"},"outputs":[{"data":{"text/plain":["((608, 10, 96, 144, 4),\n"," (608, 1, 96, 144),\n"," (118, 10, 96, 144, 4),\n"," (118, 1, 96, 144))"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["vars_to_predict = ['tas', 'diurnal_temperature_range', 'pr', 'pr90']\n","simus = ['ssp126',\n","         'ssp370',\n","         'ssp585',\n","         'hist-GHG',\n","         'hist-aer']\n","slider = 10  # sliding time window\n","\n","# Selects all of 2081-2100 data as validation\n","#val_idx = list(range(75,86)) + list(range(161,172)) + list(range(403,414))\n","\n","# Selects first two years of every decade from 2050 onward as validation\n","'''\n","val_idx = np.concatenate((np.arange(44,85,10), np.arange(45,86,10),\n","                          np.arange(130,171,10), np.arange(131,172,10), \n","                          np.arange(372,413,10), np.arange(373,414,10)))\n","'''\n","\n","# Selects first three years of every decade from 2050 onward as validation\n","'''\n","val_idx = np.concatenate((np.arange(44,85,10), np.arange(45,86,10), np.arange(46,77,10),\n","                          np.arange(130,171,10), np.arange(131,172,10), np.arange(132,163,10),\n","                          np.arange(372,413,10), np.arange(373,414,10), np.arange(374,405,10)))\n","'''\n","\n","# Selects first two years of every decade from 2020 onward as validation\n","'''\n","val_idx = np.concatenate((np.arange(14,85,10), np.arange(15,86,10),\n","                          np.arange(100,171,10), np.arange(101,172,10), \n","                          np.arange(342,413,10), np.arange(343,414,10)))\n","'''\n","\n","# Selects first two years of every decade from 1850 onward as validation\n","val_idx = np.concatenate((np.arange(4,85,10), np.arange(5,86,10),\n","                          np.arange(90,171,10), np.arange(91,172,10), \n","                          np.arange(332,413,10), np.arange(333,414,10),\n","                          np.arange(414,565,10), np.arange(415,566,10),\n","                          np.arange(570,721,10), np.arange(571,722,10)))\n","\n","# Selects continuous chunk of data from 2000s as validation\n","#val_idx = np.concatenate((np.arange(0,45), np.arange(86,131), np.arange(328,373)))\n","\n","X_train_dict = {}\n","Y_train_dict = {}\n","X_val_dict = {}\n","Y_val_dict = {}\n","\n","# Create training data\n","for var in vars_to_predict:\n","  X, Y, meanstd_inputs = create_training_data(simus, var_to_predict=var)\n","    \n","  X_val = np.take(X, val_idx, axis=0)\n","  X_train = np.delete(X, val_idx, axis=0)\n","  Y_val = np.take(Y, val_idx, axis=0)\n","  Y_train = np.delete(Y, val_idx, axis=0)\n","    \n","  X_train_dict[var] = X_train\n","  X_val_dict[var] = X_val\n","  Y_train_dict[var] = Y_train\n","  Y_val_dict[var] = Y_val\n","\n","# Open, reformat, and normalize test data\n","X_test = xr.open_mfdataset([data_path + 'inputs_historical.nc',\n","                            data_path + 'inputs_ssp245.nc']).compute()\n","Y_test = create_predictdand_data(['ssp245'])\n","\n","for input_var in ['CO2', 'CH4', 'SO2', 'BC']: \n","  var_dims = X_test[input_var].dims\n","  X_test = X_test.assign({input_var: (var_dims, normalize(X_test[input_var].data, input_var, meanstd_inputs))}) \n","    \n","X_test_np = input_for_training(X_test, skip_historical=False, len_historical=165) \n","\n","X_train_dict['tas'].shape, Y_train_dict['tas'].shape, X_val_dict['tas'].shape, Y_val_dict['tas'].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ohGQsyF0ZF9J"},"outputs":[],"source":["def get_predict_times(rmse_data, models_loc, model_type='sequential', test_data=None, repeat=10):\n","\n","  predict_times = []\n","\n","  for layer_idx in range(9):\n","\n","    predict_times_n_layer = np.array([])\n","\n","    n_layers = layer_idx + 2\n","\n","    for var_idx in range(4):\n","\n","      best_model_idx = np.argmin(rmse_data[layer_idx, var_idx])\n","      config = np.load(f'{models_loc}{n_layers}_layer_model_{best_model_idx}.npy', allow_pickle=True)\n","      \n","      model = None\n","\n","      if model_type == 'sequential':\n","        model = Sequential.from_config(config.item())\n","      elif model_type == 'functional':\n","        custom_objects = {\"ApplyPosWeight\": ApplyPosWeight}\n","        with tf.keras.utils.custom_object_scope(custom_objects):\n","          model = Model.from_config(config.item())\n","\n","      runs = timeit.repeat(stmt='model.predict(test_data, verbose=0)', repeat=repeat, number=10, globals=locals())\n","      predict_times_n_layer = np.append(predict_times_n_layer, runs)\n","\n","    predict_times_n_layer = np.reshape(predict_times_n_layer, (4, repeat))\n","    predict_times.append(predict_times_n_layer)\n","  \n","  predict_times = np.array(predict_times)\n","  \n","  return predict_times\n","\n","def plot_pred_times(means_1, sems_1, means_2, sems_2):\n","  fig, ax = plt.subplots()\n","\n","  ax.errorbar(range(2,11), means_1, sems_1, linestyle='None', marker='o', label='Dense')\n","  ax.errorbar(range(2,11), means_2, sems_2, linestyle='None', marker='o', label='RandDense')\n","  ax.legend()\n","\n","  fig.show()\n","\n","def print_stats(means_1, sems_1, runs_1, means_2, sems_2, runs_2):\n","  for i in range(9):\n","    n_layers = i + 2\n","    print(f'{n_layers} Layers:')\n","    print(f'\\t{means_1[i]} s +/- {sems_1[i]}')\n","    print(f'\\t{means_2[i]} s +/- {sems_2[i]}')\n","    print(f'\\tp-value: {round(stats.ttest_ind(runs_1[i], runs_2[i]).pvalue,3)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-QQIzkVrzZIK"},"outputs":[],"source":["# The first runs generally take longer than average for some reason,\n","# so we do a dummy run here to alleviate that issue\n","cnn_lstm_1M_total = np.load('./drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/cnn_lstm/new_metrics_experiment/1M/rmse_data_total.npy')\n","models_loc = './drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/cnn_lstm/new_metrics_experiment/1M/models/'\n","_ = get_predict_times(cnn_lstm_1M_total, models_loc, model_type='sequential', test_data=X_test_np, repeat=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"u0cxogIdkJdo"},"outputs":[],"source":["cnn_lstm_1M_total = np.load('./drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/cnn_lstm/new_metrics_experiment/1M/rmse_data_total.npy')\n","models_loc = './drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/cnn_lstm/new_metrics_experiment/1M/models/'\n","cnn_lstm_1M_predict_times = get_predict_times(cnn_lstm_1M_total, models_loc, model_type='sequential', test_data=X_test_np)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eo-n-4Jrdlj0"},"outputs":[],"source":["cnn_lstm_rand_dense_1M_total = np.load('./drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/cnn_lstm_rand_dense/new_metrics_experiment/1M/rmse_data_total.npy')\n","models_loc = './drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/cnn_lstm_rand_dense/new_metrics_experiment/1M/models/'\n","cnn_lstm_rand_dense_1M_predict_times = get_predict_times(cnn_lstm_rand_dense_1M_total, models_loc, model_type='functional', test_data=X_test_np)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SftQoQk_3VGr"},"outputs":[],"source":["np.save(results_path+f'cnn_lstm_1M_predict_times', cnn_lstm_1M_predict_times)\n","np.save(results_path+f'cnn_lstm_rand_dense_1M_predict_times', cnn_lstm_rand_dense_1M_predict_times)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"uFjTrrNwaheE"},"outputs":[],"source":["!pip install eofs --quiet\n","import numpy as np\n","import xarray as xr\n","import pandas as pd\n","from utils import *\n","from utils_cnn import *\n","results_path = results_path + 'prediction_speed/'\n","\n","from random_nn import *\n","import keras\n","from keras import Sequential, Model\n","from keras.layers import *\n","from keras.callbacks import EarlyStopping\n","import tensorflow as tf\n","from tensorflow.keras.utils import plot_model\n","tf.get_logger().setLevel('ERROR')\n","import absl.logging\n","absl.logging.set_verbosity(absl.logging.ERROR)\n","from IPython.display import display\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.ticker import AutoMinorLocator\n","import seaborn as sns\n","import timeit\n","from scipy import stats\n","\n","tf.keras.utils.set_random_seed(21)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MULw8D9FVb4F","outputId":"72e7e460-66bf-4706-ac76-802c6ad83bfb"},"outputs":[{"data":{"text/plain":["((603, 96, 144, 4), (603, 96, 144), (150, 96, 144, 4), (150, 96, 144))"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["vars_to_predict = ['tas', 'diurnal_temperature_range', 'pr', 'pr90']\n","simus = ['historical', 'hist-GHG', 'hist-aer', 'ssp126', 'ssp370', 'ssp585',]\n","# Selects first two years of every decade from 1850 onward as validation\n","val_idx = np.concatenate((np.arange(0,161,10), np.arange(1,162,10),\n","                          np.arange(165,326,10), np.arange(166,327,10), \n","                          np.arange(330,491,10), np.arange(331,492,10),\n","                          np.arange(500,571,10), np.arange(501,572,10),\n","                          np.arange(586,657,10), np.arange(587,658,10),\n","                          np.arange(672,743,10), np.arange(673,744,10)))\n","\n","X_train_dict = {}\n","Y_train_dict = {}\n","X_val_dict = {}\n","Y_val_dict = {}\n","\n","# Create training data\n","for var in vars_to_predict:\n","  X, Y, meanstd_inputs = create_training_data(simus, var_to_predict=var)\n","    \n","  X_val = np.take(X, val_idx, axis=0)\n","  X_train = np.delete(X, val_idx, axis=0)\n","  Y_val = np.take(Y, val_idx, axis=0)\n","  Y_train = np.delete(Y, val_idx, axis=0)\n","    \n","  X_train_dict[var] = X_train\n","  X_val_dict[var] = X_val\n","  Y_train_dict[var] = Y_train\n","  Y_val_dict[var] = Y_val\n","\n","# Open, reformat, and normalize test data\n","X_test = xr.open_mfdataset([data_path + 'inputs_historical.nc',\n","                            data_path + 'inputs_ssp245.nc']).compute()\n","Y_test = create_predictdand_data(['ssp245'])\n","\n","for input_var in ['CO2', 'CH4', 'SO2', 'BC']: \n","  var_dims = X_test[input_var].dims\n","  X_test = X_test.assign({input_var: (var_dims, normalize(X_test[input_var].data, input_var, meanstd_inputs))}) \n","    \n","X_test_np = input_for_training(X_test) \n","\n","X_train_dict['tas'].shape, Y_train_dict['tas'].shape, X_val_dict['tas'].shape, Y_val_dict['tas'].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4V4NcXiRavhk"},"outputs":[],"source":["# The first runs generally take longer than average for some reason,\n","# so we do a dummy run here to alleviate that issue\n","cnn_1M_total = np.load('./drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/cnn/new_metrics_experiment/1M/rmse_data_total.npy')\n","models_loc = './drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/cnn/new_metrics_experiment/1M/models/'\n","_ = get_predict_times(cnn_1M_total, models_loc, model_type='sequential', test_data=X_test_np, repeat=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"FmWlz-VJavhl"},"outputs":[],"source":["cnn_1M_total = np.load('./drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/cnn/new_metrics_experiment/1M/rmse_data_total.npy')\n","models_loc = './drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/cnn/new_metrics_experiment/1M/models/'\n","cnn_1M_predict_times = get_predict_times(cnn_1M_total, models_loc, model_type='sequential', test_data=X_test_np)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"iF9vcMT6avhl"},"outputs":[],"source":["cnn_rand_dense_1M_total = np.load('./drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/cnn_rand_dense/new_metrics_experiment/1M/rmse_data_total.npy')\n","models_loc = './drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/cnn_rand_dense/new_metrics_experiment/1M/models/'\n","cnn_rand_dense_1M_predict_times = get_predict_times(cnn_rand_dense_1M_total, models_loc, model_type='functional', test_data=X_test_np)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Sil55bawavhl"},"outputs":[],"source":["np.save(results_path+f'cnn_1M_predict_times', cnn_1M_predict_times)\n","np.save(results_path+f'cnn_rand_dense_1M_predict_times', cnn_rand_dense_1M_predict_times)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PJ7qFuO0esUT"},"outputs":[],"source":["!pip install eofs --quiet\n","import numpy as np\n","import xarray as xr\n","import pandas as pd\n","from utils import *\n","results_path = results_path + 'prediction_speed/'\n","\n","from random_nn import *\n","import keras\n","from keras import Sequential, Model\n","from keras.layers import *\n","from keras.callbacks import EarlyStopping\n","import tensorflow as tf\n","from tensorflow.keras.utils import plot_model\n","tf.get_logger().setLevel('ERROR')\n","import absl.logging\n","absl.logging.set_verbosity(absl.logging.ERROR)\n","from IPython.display import display\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.ticker import AutoMinorLocator\n","import seaborn as sns\n","import timeit\n","from scipy import stats\n","\n","tf.keras.utils.set_random_seed(21)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bNnr-kCmfNBl","outputId":"51981531-638e-4383-8854-664d6003976e"},"outputs":[{"data":{"text/plain":["((603, 12), (603, 13824), (150, 12), (150, 13824))"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["vars_to_predict = ['tas', 'diurnal_temperature_range', 'pr', 'pr90']\n","# Selects first two years of every decade from 1850 onward as validation\n","val_idx = np.concatenate((np.arange(0,161,10), np.arange(1,162,10),\n","                          np.arange(165,326,10), np.arange(166,327,10), \n","                          np.arange(330,491,10), np.arange(331,492,10),\n","                          np.arange(500,571,10), np.arange(501,572,10),\n","                          np.arange(586,657,10), np.arange(587,658,10),\n","                          np.arange(672,743,10), np.arange(673,744,10)))\n","\n","# Create training data\n","train_files = ['historical', 'hist-GHG', 'hist-aer', 'ssp126', 'ssp370', 'ssp585']\n","X, solvers = create_predictor_data(train_files, sort_by_time=False)\n","Y = create_predictdand_data(train_files, sort_by_time=False)\n","original_shape = Y['tas'].shape  # choice of tas here is arbitrary\n","\n","X_train_dict = {}\n","Y_train_dict = {}\n","X_val_dict = {}\n","Y_val_dict = {}\n","\n","for var in vars_to_predict:\n","  Y_var = Y[var].data.reshape((Y[var].shape[0], -1))\n","  Y_var = pd.DataFrame(Y_var)\n","    \n","  X_val = X.iloc[val_idx]\n","  X_train = X.drop(index=val_idx)\n","  Y_val = Y_var.iloc[val_idx]\n","  Y_train = Y_var.drop(index=val_idx)\n","    \n","  X_train_dict[var] = X_train\n","  X_val_dict[var] = X_val\n","  Y_train_dict[var] = Y_train\n","  Y_val_dict[var] = Y_val\n","\n","# Create test data\n","X_test = get_test_data('ssp245', solvers)\n","Y_test = create_predictdand_data(['ssp245'])\n","\n","X_train_dict['tas'].shape, Y_train_dict['tas'].shape, X_val_dict['tas'].shape, Y_val_dict['tas'].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"v3faYD2TfRvD"},"outputs":[],"source":["# The first runs generally take longer than average for some reason,\n","# so we do a dummy run here to alleviate that issue\n","dense_1M_total = np.load('./drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/dense/new_metrics_experiment/1M/rmse_data_total.npy')\n","models_loc = './drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/dense/new_metrics_experiment/1M/models/'\n","_ = get_predict_times(dense_1M_total, models_loc, model_type='sequential', test_data=X_test, repeat=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"riQeB5YFfRvE"},"outputs":[],"source":["dense_1M_total = np.load('./drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/dense/new_metrics_experiment/1M/rmse_data_total.npy')\n","models_loc = './drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/dense/new_metrics_experiment/1M/models/'\n","dense_1M_predict_times = get_predict_times(dense_1M_total, models_loc, model_type='sequential', test_data=X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PQ7nL4SlfRvE"},"outputs":[],"source":["rand_dense_1M_total = np.load('./drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/rand_dense/new_metrics_experiment/1M/rmse_data_total.npy')\n","models_loc = './drive/My Drive/Colab Notebooks/USC Random NN/experimental_results/rand_dense/new_metrics_experiment/1M/models/'\n","rand_dense_1M_predict_times = get_predict_times(rand_dense_1M_total, models_loc, model_type='functional', test_data=X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"A2esprAqfRvE"},"outputs":[],"source":["np.save(results_path+f'dense_1M_predict_times', dense_1M_predict_times)\n","np.save(results_path+f'rand_dense_1M_predict_times', rand_dense_1M_predict_times)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyM4Qh817rhnc2sVBpFRCGz9"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}